{
    "contents" : "setMethod(f=\"fitBMA\",  # setMethod specifies the function fitBMA()\n          definition=function(Y, X, g=3){ # g=3 is default \n            Y <- (Y-mean(Y))/sd(Y) # Standardize dependent variable\n            X <- (X-mean(X))/sd(X) # Standardize covariates\n            Z <- list()  # Z will contain every combination of X\n            coefficientsList <- list() # This will be transformed to coefficients which is a matrix\n            coefficients<-matrix(NA, ncol(X), ncol(X)) # We want the output of coefficients as a matrix; Since we will run regressions without constant, the output has the same number of rows and columns\n            R2 <- eBetaModel <- bayesF <- numeric() # Empty numerics for several statistics\n            for (i in 2:ncol(X)){ # The first elements are not looped to make it easy to create every combination of the covariates\n              Z[[1]] <- X[,1]  \n              Z[[i]] <- cbind(X[,i],Z[[i-1]]) # This ensures that Z will contain every combination of the covariates\n              coefficientsList[[1]] <- summary(lm(Y ~ Z[[1]]-1))$coef[,1] # The first element for coefficient is not looped \n              coefficientsList[[i]] <- summary(lm(Y ~ Z[[i]]-1))$coef[,1] # We should run regressions with no constant\n              coefficients[1,] <- c(coefficientsList[[1]], rep(NA, ncol(X)-length(coefficientsList[[1]]))) # Now, we want to transform coef to the form of matrix\n              coefficients[i,] <- c(coefficientsList[[i]], rep(NA, ncol(X)-length(coefficientsList[[i]]))) # An empty cell will be expressed as \"NA\"\n              R2[1] <- summary(lm(Y ~ Z[[1]]-1))$r.squared # The first element for R2 is not looped\n              R2[i] <- summary(lm(Y ~ Z[[i]]-1))$r.squared # We should run regressions with no constant\n            }\n            for (k in 1:ncol(X)){\n              p=k  # p indicates the number of covariates of the model under consideration\n              n=nrow(X)  # n indicates the number of rows of input data for explnatory variables\n              bayesF[k] <- (1+g)^((n-p-1)/2)*(1+g*(1-R2[k]))^(-(n-1)/2) # This returns Bayes's factor for the models; This is the posterior model odds for each model\n            }\n            for (j in 1:ncol(X)){\n              eBetaModel[j] <- mean((g/(g+1))*coefficients[j:ncol(X),1]) # This returns E(\\beta_j|M_k) from Slide 3\n            }\n            postModel <- bayesF/sum(bayesF) # Posterior probability of the model; The total weight assigned to all models that include each variable; This gives us the posterior probability that the coefficient is non-zero\n            postCoef <- postModel*eBetaModel # Posterior expected value of each coefficient\n            output <- list(coefficients, R2, bayesF, postCoef, postModel)  \n            names(output) <- c(\"coefficients\", \"R.squared\", \"postOdds\", \"postCoef\", \"probSig\")  # postOdds from bayesF; probSig from postModel\n            return((new(\"BMA\", Y=Y, X=X, output=output)))\n          }\n)\n\n\n",
    "created" : 1395437162192.000,
    "dirty" : true,
    "encoding" : "",
    "folds" : "",
    "hash" : "4074209648",
    "id" : "CA98D323",
    "lastKnownWriteTime" : 0,
    "path" : null,
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled4"
    },
    "source_on_save" : false,
    "type" : "r_source"
}