{
    "contents" : "definition= function(Y, X, g=3, parallel=FALSE, ...){\n  Y <- (Y-mean(Y))/sd(Y) # Standardize dependent variable\n  X <- (X-mean(X))/sd(X) # Standardize covariates\n  data <- data.frame(cbind(Y,X)) # Create a data set\n  p <- ncol(X) # p indicates the number of covariates of the model under consideration\n  id <- unlist(lapply(1:p, function(z) combn(1:p, z, simplify=F)), recursive=FALSE) # This ensures that Z will contain every combination of the covariates.\n  colNam <- names(data)[-1] # Define the name of columns of data\n  require(plyr)\n  formula <- llply(id, function(f) paste(names(data)[1],\"~\", paste(colNam[f], collapse=\"+\"),\"-1\", sep=\"\")) # formula will contain every combination of regressions. It is important to include \"-1\" to ensure that we will drop the intercept when we run regressions using this formula \n  formula[[2^p]] <- paste(names(data)[1],\"~\", \"1\", sep=\"\")   # The last element of formula will be the null model (i.e., The model including only the intercept) Since we standardized the data input, the regression coefficient of this intercept will be zero\n  beta <- matrix(NA, nrow=length(formula), ncol=ncol(X))   # This will contain the coefficients. Since we will not include the intercept, the number of columns of this matrix is the same as the number of colums of the data\n  colnames(beta) <- c(names(data)[-1]) \n  R2 <- postModel <- rep(NA, length(formula))\n  eBetaModel <- bayesF <- numeric() # Empty numerics for several statistics \n  for (i in 1:length(formula)){ # This for loop ensures that we run regressions of every possible combination\n    fit = lm(formula(formula[[i]]), data)  \n    coefficients <- coef(fit) \n    beta[i, colnames(beta) %in% names(coefficients)] <- coefficients[names(coefficients) %in% colnames(beta)] # The rows of beta contain coefficients for each iteration\n    R2[i] <- summary(fit)$r.squared # This returns the value of R^2\n  } \n  for (k in 1:length(formula)){\n    p=p  # p indicates the number of covariates of the model under consideration\n    n=nrow(X)  # n indicates the number of rows of input data for explnatory variables\n    bayesF[k] <- (1+g)^((n-p-1)/2)%*%(1+g*(1-R2[k]))^(-(n-1)/2) # This returns Bayes's factor for the models; This is the posterior model odds for each model\n  }\n  beta[is.na(beta)] <- 0 # This is to make it possible to caluclate eBetaModel below by replacing NA with 0\n  eBetaModel <- (g/(g+1))*beta # This returns E(\\beta_j|M_k) from Slide 3\n  postModel <- bayesF/sum(bayesF) # Posterior probability of the model; The total weight assigned to all models that include each variable; This gives us the posterior probability that the coefficient is non-zero\n  postCoef <- postModel%*%eBetaModel # Posterior expected value of each coefficient\n  output <- list(coefficients, R2, bayesF, postCoef, postModel)  \n  names(output) <- c(\"coefficients\", \"R.squared\", \"postOdds\", \"postCoef\", \"probSig\")  # postOdds from bayesF; probSig from postModel\n  return((new(\"BMA\", Y=Y, X=X, output=output)))\n}\n  \n  \n  \n  # Store the coefficients values in the matrix coefs.\n  coefs <- beta\n  \n  # (2) Posterior Odds\n  # Set up for the second part\n  n <- nrow(data)\n  \n  # P is a vector of the number of covariates included in each model. \n  P <- aaply(beta, .margins=1, .fun=function(x){\n    length(which(!is.na(x)))\n  }, .parallel=parallel\n  ) # close apply\n  \n  \n  # First, calculate the numerator of posterior odds, denoted as B. I divide up the numerator into two terms, first.term, and second.term. These two will be vectors of length 2^(the number of covariates)\n  #            N <- rep(n, length(formula))\n  g <-3\n  \n  first.term <- (1+g)^((n-P-1)/2)\n  second.term <- (1+g*(1-(R.sq)^2))^((-(n-1))/2)\n  # The numerator of posterior odds, B, is a vector consists of diagonal elements of the outer product of two vectors, first.term and second.terms.\n  B <- diag((1+g)^((n-p-1)/2) %o%(1+g*(1-(R2)^2))^((-(n-1))/2))\n  # The denominator of posterior odds, B, is the sum of elements of B, and we can also obtain this by innerproduct of two vectors first.term and second.term\n  sum.B <-((1+g)^((n-p-1)/2))%*%(1+g*(1-(R2)^2))^((-(n-1))/2)\n  # post.odds, a vector of length 2^(the number of covariates) will contain the posterior odds of each model.\n  post.odds <- B/sum.B\n  \n  # (3) Posterior expected value of each coefficient\n  # Replace the NAs in the beta matrix to zero. It does make sense to do so, since the coefficient of a variable not included in the model will be zero.\n  beta[is.na(beta)] <- 0\n  # Calculate expected value of each coefficient given the model. This is calculated by assigning weights to each OLS estimate of coefficients. The number of row of resulting matrix is equal to the number of models, and each column represents covariates. \n  e.beta <- g/(g+1) * beta\n  # By multiplying posterior odds of model k with the expected value of a coefficient j in model k, and taing the sum of these across all model space, we can get the posterior expected value of each coefficient. The vector post.beta of length equal to the number of covariates (including intercept) will report these values. j-th element of the vector post.beta represents the posterior expected value of coefficient of the covariate j. \n  post.beta <- post.odds %*% e.beta   \n  \n  #(4) Posterior probability that the coefficient is non-zero. \n  beta[beta!=0] <- 1\n  post.nonzero <- post.odds %*% beta\n  \n  return(new(\"BMA\", coefs=coefs, R.squared=R.sq, post.odds=post.odds, post.beta=post.beta, post.nonzero=post.nonzero))\n}\n)\n",
    "created" : 1395434176492.000,
    "dirty" : true,
    "encoding" : "",
    "folds" : "",
    "hash" : "85437529",
    "id" : "E96B7DA",
    "lastKnownWriteTime" : 140611238894592,
    "path" : null,
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled2"
    },
    "source_on_save" : false,
    "type" : "r_source"
}